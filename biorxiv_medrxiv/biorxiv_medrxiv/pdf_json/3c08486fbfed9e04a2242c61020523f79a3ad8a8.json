{
    "paper_id": "3c08486fbfed9e04a2242c61020523f79a3ad8a8",
    "metadata": {
        "title": "A Bayesian Logistic Growth Model for the Spread of COVID-19 in New York",
        "authors": [
            {
                "first": "Svetoslav",
                "middle": [],
                "last": "Bliznashki",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sofia University",
                    "location": {
                        "settlement": "Sofia",
                        "country": "Bulgaria"
                    }
                },
                "email": "valsotevs@gmail.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "We use Bayesian Estimation for the logistic growth model in order to estimate the spread of the coronavirus epidemic in the state of New York. Models weighting all data points equally as well as models with normal error structure prove inadequate to model the process accurately. On the other hand, a model with larger weights for more recent data points and with t-distributed errors seems reasonably capable of making at least short term predictions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "1. Introduction. The logistic growth model is frequently used in order to model the spread of viral diseases and of covid-19 in particular (e.g. Batista, 2020; Wu et al., 2020) . The differential equation is given in (1):",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 159,
                    "text": "Batista, 2020;",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 160,
                    "end": 176,
                    "text": "Wu et al., 2020)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "where C is the cumulative number of infected individuals, r is the infection rate, and K is the upper asymptote (i.e. the upper limit of individuals infected during the epidemic). Unlike other models, like SIR, Eq. 1 has an explicit analytical solution:",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "( )",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "where A=(K-C 0 )/C 0 and C 0 is the initial number of infectees.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The parameters of Eq. 2 can easily be estimated via Least Squares (LS) but in this note we use a Bayesian approach which allows us to make use of explicit posterior distributions in order to make probabilistic predictions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "We apply the above model to the state of New York which represents a relatively geographically homogenous population with sufficient data points in order build a reliable model which is not affected by different trends present in different regions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "2. Simulation 1. We begin with a simple model which estimates the parameters of Eq.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "2 based on the assumption of normally distributed homoscedastic errors. We use the data for 28 consecutive days of the epidemic beginning with the 4 th of March (11 infectees) and ending with the 31 st of March (75832 infectees) 1 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Prior to estimation we standardized our data by dividing all data points by 70000 in order to avoid numerical problems; after the posteriors were obtained we back-transformed the results in their original scale.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "We assumed that the errors are normally distributed with mean equal to 0 and standard deviation (\u03c3) estimated by the model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "We used the blockwise Random Walk Metropolis algorithm 2 in order to sample from the joint posterior distribution of the four parameters of the model (K, A, r, and \u03c3). The proposal distribution was multivariate normal with scaled variance-covariance matrix estimated on the basis of pilot runs. Uninformative improper uniform priors ranging from 0 to + \u221e were employed for all parameters in the model. A pilot chain showed an acceptance rate within the optimal range of 23% (e.g. Chib & Greenberg, 1995 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 480,
                    "end": 502,
                    "text": "Chib & Greenberg, 1995",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20054577 doi: medRxiv preprint explained above) in order to avoid clutter. The same is true for the scale parameter described in Section 4 ( . We see that the estimates are very similar to the posterior EAPs reported above which is to be expected given the uninformative nature of our priors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Still, the Bayesian analysis gives slightly wider intervals for the estimates which as we'll see below is a positive. Table 1 . The values on the x-axis represents number of days since the initial data point used in our model (March the 4th).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 118,
                    "end": 125,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Both Fig. 1 (top) and Fig. 2 show that the model's estimates (e.g. K) are very conservative. This is a commonly observed situation for phenomenological (i.e. purely datadriven) models of this type.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 5,
                    "end": 17,
                    "text": "Fig. 1 (top)",
                    "ref_id": null
                },
                {
                    "start": 22,
                    "end": 28,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "At the time of writing this note, there is information for the number of infectees three days after the 28 days used in order to fit the model. We used the posterior estimates in order to predict the number of future infectees. More precisely, we used the posterior estimates (including \u03c3) in order to simulate data for future values of t thereby constructing what is known as posterior predictive distributions. For example, for a given future day (e.g. for the 28 th day) we sampled all posterior values for Eq. 2 parameters and for each sample we plugged in the t=28 value in order to obtain a mean prediction value; then we added a random number generated from N(0, \u03c3) where the value for \u03c3 is sampled from the posterior alongside the other parameters available for the given step. The resulting predictive distribution has an observed mean, variance, etc. and can be used in order to make point and/or interval predictions (HDIs) as usual. Some results are shown in Table 2 We see that the predictive distributions fail to capture even the immediate true value which once again suggests that indeed the model is inadequate and fails to capture the true trends in the data. Note, however, that the ranges of the prediction intervals increase for later data points which is a desirable quality of a model and is intrinsic to the Bayesian approach employed here. As Fig. 2 (upper right portion) suggests, the model converges too quickly to its upper asymptote and hence its predictions are too low and probably too narrow. This observation is not surprising given that it is well-known that the simple logistic model is applicable only during specific stages of an outbreak and/or when enough data is available (see Wu et al, 2020 for a review). Possible solutions include: improving the model (e.g. Richards, 1959) by adding more parameters which can account better for the deviation of the observed data points from the symmetric S-shaped curve suggested by the logistic growth model; adjusting the prior distributions so as to reflect our expectations of a much higher . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 1802,
                    "end": 1817,
                    "text": "Richards, 1959)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [
                {
                    "start": 971,
                    "end": 978,
                    "text": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 1368,
                    "end": 1374,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20054577 doi: medRxiv preprint upper asymptote (K); switching to a different, preferably more mechanistic approach altogether.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Instead, we attempted to construct a more accurate model within the same logistic growth paradigm in a different way: we introduced weights to our data points with later data points receiving higher weights than older ones in the hope that this will alleviate some of the problems observed above. Specifically, we weighted the points according to a Rectified Linear-like function (e.g. Glorot et al., 2011) whereby the first 20 observations received constant (0.008) low weights and the last 8 observations received linearly increasing higher weights (last 8 weights=[0.77 1.55 2.32 3.09 3.87 4.64 5.41 6.19]). The idea behind this scheme was to try to force the model to account better for the observations following the approximately linear trend observed in the upper half of Fig. 2 . Note also that the weights sum to the number of original observations (28). The weights pattern is shown in Fig. 3 . In the subsequent simulations we used the proposed weights in order to weigh the likelihood function of the model. Following Simeckova (2005) , assuming we have observations Y 1 , \u2026Y n and Y i has density f i (Y i |\u03b8) where \u03b8 is the vector of parameters (see Eq.",
            "cite_spans": [
                {
                    "start": 386,
                    "end": 406,
                    "text": "Glorot et al., 2011)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1030,
                    "end": 1046,
                    "text": "Simeckova (2005)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [
                {
                    "start": 779,
                    "end": 785,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 896,
                    "end": 902,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "2), we apply the weights vector w=[w 1 ,\u2026w n ]. If we let l i (\u03b8)=log(f i (Y i |\u03b8)), the weighted loglikelihood function of our model becomes: . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20054577 doi: medRxiv preprint l(\u03b8)=\u03a3w i .l i (\u03b8)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "3. Simulation 2. We used the above weighing scheme and repeated the previous simulation. In that sense we altered the likelihood function while leaving the prior distributions intact. Everything else (including the simulation details such as number of posterior draws, thinning, etc.) was the same as reported in Section 2. Again, we observed good convergence for all parameters (see Fig. 4 depicting a traceplot and a histogram for the K parameter). . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 384,
                    "end": 390,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20054577 doi: medRxiv preprint Figure 4 . A histogram (top) and a traceplot (bottom) for the posterior for the K parameter from Eq. 2 for our second model. Table 3 gives a summary for the posterior estimates 3 . We see that our weighting scheme appears to give more reasonable results and that the estimates for the upper asymptote (K) are substantially higher than before. The same observations can be made when we inspect the fitted equation against the observed data (Fig. 5) . It is clear that the fitted curve is much more affected by the later points and consequently the upper asymptote is higher than before (compare also Tables 3 and 1). is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 107,
                    "end": 115,
                    "text": "Figure 4",
                    "ref_id": null
                },
                {
                    "start": 232,
                    "end": 239,
                    "text": "Table 3",
                    "ref_id": null
                },
                {
                    "start": 546,
                    "end": 554,
                    "text": "(Fig. 5)",
                    "ref_id": null
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . https: //doi.org/10.1101 //doi.org/10. /2020 We see that this time the model accurately predicts two consequent data points and fails to predict the third. This is still not a satisfactory performance, however, and hints towards the possibility that the actual process exhibits steeper rise than the one suggested by the model. In the same way, it appears that the HDIs are not wide enough in order to accommodate the actual uncertainty.",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 65,
                    "text": "//doi.org/10.1101",
                    "ref_id": null
                },
                {
                    "start": 66,
                    "end": 85,
                    "text": "//doi.org/10. /2020",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Looking at figures 2 and 5 we see that the errors, in all likelihood, both lack homoscedasticity and possess an auto-correlated structure. In order to (partially) alleviate these problems we removed the normality assumption present above and replaced it with the assumption that the errors follow a t-distribution with location parameter equal to 0 and scale (similar to the standard deviation used above) and degrees of freedom (df) parameters estimated from the data (see Kruschke, 2012 for the same approach in the context of a linear model).",
            "cite_spans": [
                {
                    "start": 474,
                    "end": 488,
                    "text": "Kruschke, 2012",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Simulation 3."
        },
        {
            "text": "We used the same weighing scheme as above and introduced the two new parameters (scale and df) describing the t-distribution governing the model's errors. We again proposed the first four parameters of the model (i.e. K, A, r, scale) by a multivariate normal distribution centered on the previous values of the chain with scaled variance-covariance matrix estimated from pilot chains; the df parameter was proposed separately based on a lognormal . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation 3."
        },
        {
            "text": "The copyright holder for this preprint . https://doi.org/10.1101/2020.04.05.20054577 doi: medRxiv preprint distribution 4 which was transformed back to the original scale after the end of the simulation. 30 million samples from the posterior were obtained with every 300 th step retained (i.e. we had a thinning parameter of 300). We used improper uniform priors for all parameters except for the df parameter for which a shifted exponential with mean equal to 30 was specified as suggested by Kruschke (2012) .",
            "cite_spans": [
                {
                    "start": 494,
                    "end": 509,
                    "text": "Kruschke (2012)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The results indicated good convergence (a traceplot for the K parameter is shown in Fig. 6 below; histograms from the posterior for all parameters are shown in Appendix A). Table 5 gives the point and interval estimates for the posteriors for the five parameters in question. We see that the estimates differ substantially from the ones reported above and that a steeper curve is indicated. The lognormal distribution is not symmetric and hence we use the actual Metropolis-Hastings acceptance probability (e.g. Chib & Greenberg, 1995) during the step sampling from the df posterior. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 512,
                    "end": 535,
                    "text": "Chib & Greenberg, 1995)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 84,
                    "end": 90,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 173,
                    "end": 180,
                    "text": "Table 5",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . https: //doi.org/10.1101 //doi.org/10. /2020 Table 5 . Means, medians, standard deviations (SD), and 95% HDIs for the parameters of Eq. 2 obtained from the posterior of our last model. Consistently with our expectations the 95% HDI for the df parameter suggests a noticeable deviation from normality. Fig. 7 shows the predicted trend based on the EAP estimates shown in Table 5 .",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 65,
                    "text": "//doi.org/10.1101",
                    "ref_id": null
                },
                {
                    "start": 66,
                    "end": 85,
                    "text": "//doi.org/10. /2020",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 86,
                    "end": 93,
                    "text": "Table 5",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 342,
                    "end": 348,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 411,
                    "end": 418,
                    "text": "Table 5",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Finally, Table 6 specifies the predictive distributions for the next 7 days and for the estimate for the final cumulative number of infectees. We see that this model accurately predicts at least three future data points. In the next several days we should be able to observe how the model deals with data points further away in time. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 16,
                    "text": "Table 6",
                    "ref_id": "TABREF8"
                }
            ],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "The copyright holder for this preprint . As can be seen in Appendix A the posteriors for the different parameters no longer resemble parametric distributions (for the previous two models the posteriors for the K, A, and r definitely resemble normal/t-distributions while the \u03c3 parameter is pronouncedly positively skewed and thus resembles a gamma distribution). Nevertheless this model appears to be best suited for the modeled phenomenon.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not peer-reviewed)"
        },
        {
            "text": "Discussion. It appears that a logistic growth model with a weighted likelihood function and a t-distribution imposed on the error structure is able to make accurate short term predictions of the spread of a disease. The Bayesian estimation gives more accurate estimates than traditional Least Squares and Maximum Likelihood approaches with more accurate interval estimates. Moreover, the Bayesian posteriors (including the predictive distributions) have a straightforward probabilistic interpretation which cannot be said about traditional frequentist Confidence Intervals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "As a rule, the posterior distributions show high correlations between the parameters which makes algorithms like blockwise Metropolis-Hastings more effective in general than algorithms which explore a single posterior distribution at a time such as the Gibbs Sampler and the componentwise Metropolis-Hastings. The fact that some posteriors lack closed-form solutions is another impediment when it comes to the Gibbs Sampler but not necessarily for the use of the componentwise Metropolis-Hastings with respect to certain parameters as demonstrated in Section 3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "The weighing scheme employed here proves beneficial over modeling the raw data by forcing the model to pay more attention to more recent observations. Other weighing schemes are certainly possible and investigating the properties of different approaches seems a potentially fruitful future enterprise.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "As a whole it appears that the combination of Bayesian Estimation, differentially weighing the observations, and employing a more robust approach towards modeling the %%%%%%%%%%%%%%%Proposal Covariance Matrix%%%%%%%%%%%%%%%% %should be imported as covmat to Matlab before running the above program; %%%%%Function calculating the density for the Generalized t-distribution%%%%%%%% %the function is used to calculate the likelihood; function y = gentdst(x, m, s, v) %x -data point, m -location, s -scale, v 0 degrees of freedom; c=(1/sqrt(v))*(1/(beta(v/2, 0.5))); y=(c/s)*(1+((x-m).^2)/(v*(s^2))).^(-0.5*(v+1));",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Estimation of the Final Size of Coronavirus Epidemic by the Logistic Model. medRxiv",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Batista",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Understanding the Metropolis-Hastings Algorithm",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chib",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Greenberg",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Deep Sparse Rectifier Neural Networks. Proceedings of the 14 th International Conference on Artificial Intelligence and Statistics",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bordes",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "15",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Bayesian Estimation Supersedes the t test",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kruschke",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Journal of Experimental Psychology: General",
            "volume": "142",
            "issn": "2",
            "pages": "573--603",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "A Flexible Growth Function for Empirical Use",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Richards",
                    "suffix": ""
                }
            ],
            "year": 1959,
            "venue": "Journal of Experimental Botany",
            "volume": "10",
            "issn": "29",
            "pages": "290--301",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Maximum Weighted Likelihood Estimation in Logistic Regression",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Simeckova",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "WDS'05 Proceedings of Contributed Papers",
            "volume": "1",
            "issn": "",
            "pages": "144--148",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Generalized Logistic Growth Modeling of the COVID-19 Outbreak in 29 Provinces in China",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Darcet",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sornette",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "the rest of the World. arXiv",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "below shows the observed and the fitted estimates for the cumulative number of infectees in New York.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Observed cases (circles) and fitted values (continuous grey line) based on the EAP estimates for the parameters reported in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The Rectified Linear pattern of weights used to weigh the likelihood function in our second and third simulations. The x-axis denotes the consecutive number of each observation and the y-axis shows its weight. See the text for the actual values employed.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Traceplot for the posterior for the K parameter from Eq. 2 for our final model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Observed cases (circles) and fitted values (continuous grey line) based on the EAP estimates for the parameters reported in",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "). The final simulation used 20 million iterations and heavy thinning (each 200 th sample was retained). The traceplots and autocorrelation functions indicated excellent convergence. A histogram and a traceplot for the K parameter are shown in Fig. 1.Table 1. Shows the mean (Expected Aposteriori -EAP) and median estimates for the 4 parameters as well as their standard deviations and 95% Highest Density Intervals (HDI).",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Means, medians, standard deviations (SD), and 95% HDIs for the parameters of Eq. 2 obtained from the posterior of our first model.Note that inTable 1and in subsequent tables of this type the \u03c3 parameter and its posterior SD are given in the standardized scale (the original data was divided by 70000 as",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": ". The K parameter is always given in its original (unstandardized) form since it is of primary interest.For comparison, the estimates obtained from LS estimation (via the Matlab's cftool)",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 2. 95% and 99% HDIs for the predictive distributions for 7 days after the finaldata point used to fit the model. Ranges for the HDIs are given below the upper values for a given interval. The true values available by now are shown on the last row. The last column (day 200) gives the posterior prediction for the final number of infectees.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 3. Means, medians, standard deviations (SD), and 95% HDIs for the parameters of Eq. 2 obtained from the posterior of our second (weighted) model.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "gives the posterior predictive distribution for 7 days ahead as well as for the estimate for the final number of infectees.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "95% and 99% HDIs for the predictive distributions for 7 days after the final data point used to fit our last model. Ranges for the HDIs are given below the upper values for a given interval. The true values available by now are given at the last row (the values in bold are accurately predicted by the model). The last column (day 200) gives the posterior prediction for the final number of infectees.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "errors (i.e. assuming a t-distribution with scale and df parameters estimated from the data) results in more reliable HDIs and prediction intervals than more traditional approaches.Far from being perfect, the proposed model appears to be somewhat useful. Of course, such a model can be continuously augmented by including new data points and applying the same or similar weighing procedure. Presumably, continuously adjusting the model by adding new observations as they become available would improve its accuracy.That being said, our simulations suggest that we should be somewhat skeptical towards logistic growth models applied to the raw data describing an outbreak, especially when the number of available data points is relatively small and the upper asymptote appears not to have been approached yet.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "Histograms of the posterior distributions for the five parameters for our last model. For simplicity the scale parameter values are presented in their standardized form (i.e. they are not back-transformed). ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX A"
        },
        {
            "text": "Matlab code for the third simulation.%t, y, and covmat should be imported before running the code; t is time in days (the first day %for which there are 11 infectees is labeled 0 -March 4 th ); all consecutive days up to 27 are %simply given their corresponding numbers (i.e. 0, 1, 2, 3\u202627); y is the cumulative number %of infectees for each consecutive day up to the 31 (1)./(1+cur(2)*exp(-cur(3)*t)); cnt=0; Lp=gentdst(y, PrevPred, cur(4), exp(curdf)); Lp=sum(wei.*log(Lp)); Lp=Lp+log((1/29)*exp(-(1/29)*(exp(curdf)-1))); %posterior; for i=1:nit prop=mvnrnd(cur, covmat*0.09, 1); %proposal; if prop(1)<=0 || prop (2) Pred=cur(1)./(1+cur(2)*exp(-cur(3)*t)); Ln=gentdst(y, Pred, cur(4), exp(propdf)); Ln=sum(wei.*log(Ln)); Ln=Ln+log((1/29)*exp(-(1/29)*(exp(propdf)-1))); alp=(Ln-Lp)+(log(propdf)-log(curdf)); %accounting for the log-normal proposal; end if log(rand)<alp; curdf=propdf; Lp=Ln; end if mod(i, 300)==0 cnt=cnt+1; PAR(cnt, :)=cur; DF(cnt)=curdf; end end",
            "cite_spans": [],
            "ref_spans": [],
            "section": "APPENDIX B"
        }
    ]
}