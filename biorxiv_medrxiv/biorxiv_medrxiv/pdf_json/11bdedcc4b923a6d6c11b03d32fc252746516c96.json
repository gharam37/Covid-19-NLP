{
    "paper_id": "11bdedcc4b923a6d6c11b03d32fc252746516c96",
    "metadata": {
        "title": "Coronametrics: The UK turns the corner",
        "authors": [
            {
                "first": "Adam",
                "middle": [],
                "last": "Goli\u0144ski",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of York",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Peter",
                "middle": [],
                "last": "Spencer",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of York",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "There are many ways of analyzing the progress of an epidemic, but when it comes to short term forecasting, it is very hard to beat a simple time series regression model. These are good at allowing for the noise in day to day observations, extracting the trend and projecting it forward. * Our regression models are designed to exploit this, using the daily statistics released by PHE and NHSE. These strongly suggest that the tide has turned and that taking one day with the next, the national \u2026gures for deaths from this virus will now fall back noticeably, easing the pressure on the NHS and its sta\u00a4. * There is still a huge range of uncertainty associated with any forecast. The model is currently predicting a total of 113,000 admissions to UK hospitals by the end of April and that 19,000 people will die from the virus in English hospitals by then. There is a 1 in 20 chance that the mortality \u2026gures could \u2021atten out more quickly, with around 1,000 more deaths occurring by the end of April. However, there is the same risk that this \u2026gure continues to mount, rising to a total of 24,000 by the end of the month. On current trends, the number of deaths in the UK is likely to be 10% higher than the number in England. * Longer term, the impact of the virus will depend critically upon the likely relaxation of the current government strategy of suppression.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The UK has a great deal of expertise in modelling epidemics. Research teams at Imperial College, Oxford and UCL have developed large models that can be adapted to represent the spread of a new virus like Covid-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "These models have parameters that represent the degree of contagion, morbidity and ultimately mortality associated with any disease. They are being used to forecast the evolution of the current epidemic and : medRxiv preprint advise the government on the likely e\u00a4ect of interventions like the current lock-down. In these respects, they resemble the large-scale econometric models used by the O\u00a2 ce for Budget Responsibility and H.M. Treasury to make economic forecasts and estimate the e\u00a4ect of changes in government economic policy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "However, large models can miss important links, especially when confronted with 'black swan'events like a \u2026nancial crisis or the outbreak of an unknown virus like Covid-19. They are di\u00a2 cult to adapt to such developments and even to update in the light of new data releases from the O\u00a2 ce for National Statistics or Public Health England.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Econometricians have developed a variety of simple methods of checking the properties of these models and matching them better to the data. For example, the work of Box and Jenkins (1976) on time series led modelers to regard physical, economic, biological and other large complex systems as a black box, generating data that were best represented in terms of amorphous statistical models. The more recent vector autoregressive model methodology (Sims (1980)) o\u00a4ers a more \u2021exible way of doing this. These approaches are routinely used by City and other analysts to make their economic and \u2026nancial forecasts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The Bank of England has a suite of economic models used for di\u00a4erent tasks, ranging from large scale models for simulating the e\u00a4ects of policy changes and \u2026nancial shocks to smaller scale models used in economic and \u2026nancial forecasting.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Similarly, epidemiologists have a range of di\u00a4erent ways of modelling epidemics. Many use the logistic model to provide a simple representation of the cumulative number of infections, hospital admissions and deaths caused by an epidemic. To do this they \u2026t a logistic curve to these series. Remarkably, this model accurately predicted the evolution of the Covid-19 outbreak in Wuhan, China (Batista (2020)). However, there are well-known problems with any procedure that \u2026ts curves to series that can grow exponentially.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "In this paper, we show that these problems can be handled using techniques developed for modelling nonstationery economic data, like growth and in \u2021ation. We then apply these techniques to model the daily data issued by Public Health England (PHE) and NHS England (NHSE).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "These time-series models are relatively simple. They can be updated quickly to take account of the latest data and forecast the spread of the virus through the community. As in any forecasting context, projections need to be updated rapidly in the light of any forecasting errors. These models can distinguish the trend from misleading day-to-day movements and then use this to identify likely turning points and o\u00a4er an estimate of the \u2026nal total. They also provide estimates of the uncertainty that inevitably surrounds any forecast at the moment. Although we do not exploit this advantage in the present paper, they also provide useful statistics that summarize the virulence, morbidity and mortality rates in countries with di\u00a4erent demographic and other characteristics, allowing the e\u00a4ects of di\u00a4erent containment strategies to be estimated. This paper uses this econometric approach to track the path of the Covid-19 outbreak in the UK and predict its likely evolution. We now have enough data to say, with a reasonable degree of con\u2026dence, that 2 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Introduction the corner has been turned. We focus on the two headline statistics, the daily data released by PHE for identi\u2026ed infections and hospital deaths. Our \u2026rst model represents the likely daily number of new infections in terms of variables that represent the fractions of the population that on the one hand are likely to have been exposed to the disease and hopefully less susceptible and those that have not and remain susceptible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The regression equation tracks these data nicely, as shown by Figure 1 . The continuous line shows the way this tracks the cumulative number of cases represented by the dots. The continuation shows the path of infections predicted by this equation. We project the latest data forward dynamically given the estimated parameter values assuming that the equation tracks perfectly. This gives an estimate of nearly 113; 000 for the \u2026nal number of infections (as of 15 April 2020). According to this model, we passed the half way stage of 56; 500 in terms of infections at the beginning of April. This is the 'point of in \u2021ection'in the jargon, which is the peak of the 'bell curve'for new cases, shown by the dotted line. Our second model represents the daily mortality statistics. This sample, though smaller, represents harder data than the infections data and is obviously of crucial importance. The regression equation is depicted in Figure 2 , with an estimate of the \u2026nal number of deaths put at about 15; 500. This estimate is less well determined than in the case of infections, re \u2021ecting the shorter data sample. But with almost 13; 000 hospital deaths recorded by 15th April, it suggests that we have turned this corner too. Thus, in the 3 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 62,
                    "end": 70,
                    "text": "Figure 1",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 934,
                    "end": 942,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": ""
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . same way that the nights gradually start to shorten in January, we should now see the terrible \u2026gures for mortality begin to fall, gradually at \u2026rst but then hopefully gaining pace. Like economic forecasts, these projections are subject to a considerable degree of uncertainty. This can be assessed relatively easily in these simple models using stochastic simulations, as described in Section 6. Naturally, this uncertainty builds up with the horizon of the forecast, as the e\u00a4ect of simulated errors cumulates over time. Figures 3 and 4 show the results for the cumulative and daily number of deaths, respectively. This clearly illustrates the range of uncertainty still associated with any forecast at this stage of the epidemic. The 90% con\u2026dence band in Figure 3 shows that there is a 1 in 20 chance that this number could level out with around 1; 000 more deaths by the end of this month. But there is an equal chance of these \u2026gures continuing to mount until the end of the month, rising to a total of 18; 000. After that, the impact of the virus will depend critically upon the likely relaxation of the current government strategy of suppression.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 601,
                    "end": 616,
                    "text": "Figures 3 and 4",
                    "ref_id": null
                },
                {
                    "start": 837,
                    "end": 845,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": ""
        },
        {
            "text": "4 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . M a r 1 4 M a r 1 6 M a r 1 8 M a r 2 0 M a r 2 2 M a r 2 4 M a r 2 6 M a r 2 8 M a r 3 0 A p r 0 1 A p r 0 3 A p r 0 5 A p r 0 7 A p r 0 9 A p r 1 1 A p r 1 3 A p r 1 5 A p r 1 7 A p r 1 9 A p r 2 1 A p r 2 3 A p r 2 5 A p r 2 7 A p r 2 9 2020 0,000 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "M a r 1 4 M a r 1 6 M a r 1 8 M a r 2 0 M a r 2 2 M a r 2 4 M a r 2 6 M a r 2 8 M a r 3 0 A p r 0 1 A p r 0 3 A p r 0 5 A p r 0 7 A p r 0 9 A p r 1 1 A p r 1 3 A p r 1 5 A p r 1 7 A p r 1 9 A p r 2 1 A p r 2 3 A p r 2 5 A p r 2 7 A p r 2 9 2020 0 200 400 600 800 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 3"
        },
        {
            "text": "5 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 4"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https: //doi.org/10.1101 //doi.org/10. /2020 An econometric model is only as good as the data upon which it is based. We need to rely on the PHE statistics despite their drawbacks. The infection \u2026gure only counts those who register positive in the swab test, which has until recently focused on hospital admissions. It is likely that this is the tip of a very large iceberg. Indeed, this is currently a subject of controversy between the large scale modelling groups, showing that it is not only economists that are prone to disagreement.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 102,
                    "text": "//doi.org/10.1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 122,
                    "text": "//doi.org/10. /2020",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Figure 4"
        },
        {
            "text": "More worrying still, the PHE mortality data only cover hospital deaths and are subject to a long reporting lag. They announce the number of hospital deaths reported to it the previous day. Because relatively few deaths are reported to it on the day they occur, these announcements mainly comprise deaths in previous days. We have explored this issue using another data set released by NHS England. 1 This takes the deaths reported in England and arranges them by the date of death rather than the date of announcement. This shows that the reporting lag is very long, revealing that at any one time, there has been a large backlog of unreported deaths in England, which understate the running total and arti\u2026cially in \u2021ate the \u2026gures announced later. Our estimates, described in Appendix 1, suggest that unless these reporting delays have been signi\u2026cantly reduced, there was a staggering backlog of 4; 800 deaths that had occurred but not yet been reported by 14th April. Fortunately it seems that this lag structure is relatively stable, allowing adjustments to the NHSE data that give a good indicator of deaths as they occur. This research looks very promising and is reported in Section 5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 4"
        },
        {
            "text": "Finally, we would stress that this research is in progress and this discussion paper is not peer reviewed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 4"
        },
        {
            "text": "A new forecast methodology can only be assessed in terms of its track record over time. To help in this assessment, our daily short-term forecasts of the coronavirus mortality rates for the UK are available on our website: https://sites.google.com/york.ac.uk/adam-golinski/coronametrics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Figure 4"
        },
        {
            "text": "The basic logistic equation is nicely explained for example in Batista (2020) . His equation (1) is:",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 77,
                    "text": "Batista (2020)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "The logistic process"
        },
        {
            "text": "where: C is the accumulated number of cases, K the \u2026nal epidemic size and r 0 the propagation or infection rate.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The logistic process"
        },
        {
            "text": "To understand this equation, we can think of infections as being generated by random encounters between Susceptible people (S, who have not yet had the disease) and Infectious people (I, that are still contagious 1 We are very grateful to Chris Giles, Economics Editor of the Financial Times for suggesting we look at this.",
            "cite_spans": [
                {
                    "start": 213,
                    "end": 214,
                    "text": "1",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "The logistic process"
        },
        {
            "text": ". CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 but not self-isolating). This leaves the rest of the initial population as Removed (R), who have already had the infection and have either recovered or died. This is the model of Kermack, McKendrick, and Walker (1927 ) (originally published in 1927 and republished in 1991 . It works like a matching model for new hires in the labour market (which result from employers randomly meeting those looking for work).",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 288,
                    "end": 325,
                    "text": "Kermack, McKendrick, and Walker (1927",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 326,
                    "end": 357,
                    "text": ") (originally published in 1927",
                    "ref_id": null
                },
                {
                    "start": 358,
                    "end": 381,
                    "text": "and republished in 1991",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Initially, with C(0) cases observed when the outbreak is detected, 100% of them will be Infectious and will infect Susceptible people at the rate r per unit of time (dt) causing dC(0) = rC(0)dt new cases. Thus initially, the disease will will spread exponentially, a word which we hear a lot of in common parlance these days. Mathematically this is a very simple di\u00a4erential equation: dC(t) = rC(t)dt: However, as people recover (or die) the probability that an Infected person will meet a Susceptible one declines and amounts to",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "(1 C(t)=K)), resulting in rC(t)(1 C(t)=K)dt new cases per unit of time as shown by the equation. This equation has both positive (i.e. Infectious rC t 1 ) and negative (Removed rC 2 t 1 =K) feedback terms. In this deterministic setting C will rise inexorably until C = K. 2 This is another \u2026rst-order ordinary di\u00a4erential equation, which we can solve for the path followed by the accumulated number of cases C. This is the well-known logistic level equation familiar from the charts that we see on television:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "where: A = K=C(0) 1 (see for example Batista (2020) , equation (2)). The number of new daily cases dC(t)",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 51,
                    "text": "Batista (2020)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "is technically the derivative of this function, the \u2026gure with the bell shape in Figure 1 that the government is trying to \u2021atten to save the NHS.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 81,
                    "end": 89,
                    "text": "Figure 1",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "6"
        },
        {
            "text": "The parameters K and r can be estimated by adding an error term and \u2026tting this to daily or other time series data. However, there are at least two issues with this procedure. First, there are well-known econometric and biometric issues with \u2026tting equations like (2) to level data, which mean we should be working with di\u00a4erential equations like (1). We pick up this point in Section 2 below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Second, what accounts for the error term: is it external in \u2021uences, randomness or indeed unrealistic model assumptions? This is critical to the likely outcome. There are several possibilities. The most optimistic is that we eradicate the disease, as we did with smallpox. Next best, we might suppress the disease at a low level as has happened in Wuhan. At the other extreme, it spreads until almost everyone has been infected and is thus immune (the limit K is then the initial size of the population).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Either way, C can go up but never fall. However, in \u2021uenza can mutate in a way that having had it once, people can get it a second time. So rC=K; the fraction of the population that is Infected, can go up and down. That gives a stochastic equilibrium or steady state described by a beta distribution, which models the fraction of those Infected in a population as it varies between 0 and K. However, that involves 2 This is the Verhulst (1838) model. He used it as a deterministic model of population growth, which has similar characteristics, a slow take-o\u00a4 in from a low base, followed by fast growth and \u2026nally a slow down as equilibrium is approached. 7 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 longer-term issues that are not our immediate concern. This paper is focussed on modelling the \u2026rst wave of the coronavirus epidemic in the UK, which we are living through now. The next section is inevitably technical, but the intuition is simple: C(t) converges monotonically on K and then stays there, at least until the next outbreak.",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "If we add a Gaussian random error term dz to (1) this gives the Stochastic Logistic or Stochastic Verhulst di\u00a4usion:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "This model is extensively used to model the growth of variables like population and GDP (Merton (1975)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "Because the volatility term C(t) vanishes as C(t) tends to zero, it has a lower bound at zero. It has a Gamma distribution in steady state provided that 2r= 2 > 1: However, it is unsuitable for modelling the fraction of the population a\u00a4ected by a virus since this is bounded between zero and K, while GDP and the population itself have an in\u2026nite upper bound.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "To give the model an upper bound of unity, we also need to ensure that the variance term vanishes as C(t)=K tends to unity. For example we can use the square root volatility speci\u2026cation of Feller (1959) and",
            "cite_spans": [
                {
                    "start": 190,
                    "end": 203,
                    "text": "Feller (1959)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "used to model the lower bound on interest rates by Cox, Ingersoll, and Ross (1985) and Ahn and Gao (1999) :",
            "cite_spans": [
                {
                    "start": 51,
                    "end": 82,
                    "text": "Cox, Ingersoll, and Ross (1985)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 87,
                    "end": 105,
                    "text": "Ahn and Gao (1999)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "This means that the variance (1 C(t)=K)C(t) vanishes at both C(t) = 0 and C(t)=K = 1, ensuring that the process is bounded within the domain [0; K]. To test the e\u00a2 cacy of this speci\u2026cation we build an encompassing model that embeds this and other congruent volatility speci\u2026cations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "This is a Constant Elasticity of Variance model since the elasticity of the variance C(t) 2 1 (1 C(t)=K) 2 2 with respect to C(t) and (1 C(t)=K) terms is constant (respectively 1 and 2 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "8 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 To \u2026t this to daily data we then discretize (5) and use it to explain the number of new cases identi\u2026ed in any day:",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "where C t represents the cumulative number of deaths at time t and e t is an error term, e t N (0; 1). Given the estimates of the parameters we can then solve for the path of C and extrapolate it forward.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "This speci\u2026cation assumes that there is no signi\u2026cant infection or recovery lag between the right hand side positive and negative feedback terms and the number of infections being identi\u2026ed in the daily statistics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "However, putting in longer lags on these terms reduces the \u2026t of the regression model. This is likely because the recent data represent a larger sample that also re \u2021ects infection passed on from people that are missed by the o\u00a2 cial statistics. It may re \u2021ect other measurement errors in the data. This may also re \u2021ect behavioral feedbacks. For example, as C t grows and people hear about the spread of the virus and its consequences, they seem likely to modify their behavior in a way that mimics the e\u00a4ect of the negative 'Removed'feedback term (1 C t 1 =K), reducing the K parameter representing the \u2026nal total and perhaps speeding up the lags.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "We start the estimation sample from 27 February, when the total number of infected cases exceeded 15, since we noted that including the sample by the early period when only a few cases were recorded introduces a bias in the estimation results. Initial experiments showed that the best volatility model had optimal elasticities close to 1 = 2 = 0:75. Imposing these rounded values gave the result: ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A stochastic model"
        },
        {
            "text": "27 February 2020 -15 April (7) Standard errors are reported in small typeface. The estimate K = 113; 027 is reasonably well determined and tells us that according to this model, we are around the half way stage of K=2 = 56; 513. This is the point of in \u2021ection in Figure 1 , which is the peak of the bell curve for new cases. Thus, we should now see the number of new infections start to fall, taking one day with another.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 264,
                    "end": 272,
                    "text": "Figure 1",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "A stochastic model"
        },
        {
            "text": "Arguably a more important question is: when will we see the mortality statistics peak and at what level?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "Strictly speaking this requires a di\u00a4erent kind of model, since there should be a simple linear relationship between the number of deaths and the number of infections in earlier days. However, the PHE infections statistics record those who register positive in the swab test, which were initially targeted on hospital admissions. It is very likely that this is the tip of a very large iceberg, a subject of controversy as noted in 9 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.17.20069278 doi: medRxiv preprint the introduction. In this sense, mortality statistics could represent harder data than infections statistics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "Instead, we can extend the reasoning of the logistic infections model to track deaths instead. Suppose that deaths represent a lagged fraction of the true number of infections. Substituting this into the logistic dynamics (6) gives the model:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "where D t represents the cumulative number of deaths at time t and K is now the model parameter representing the \u2026nal total. Since the mortality record due to Covid-19 is shorter than the total number of infections, we decrease the initial threshold to 10 cases and start the sample from 14 March. In this case the best volatility model had optimal elasticities close to 1 = 2 = 0:5, giving a square root model. Imposing ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "14 March 2020 -15 April (9) The estimate K = 15; 533 is less well determined than in the case of infections, re \u2021ecting the shorter data sample.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the PHE announcements of hospital deaths"
        },
        {
            "text": "The PHE data analyzed in the previous section give the number of hospital deaths reported to it the previous day. Because relatively few deaths are reported to it on the day they occur, these mainly comprise deaths in previous days. This is apparent from another data set released by NHS England. This takes the deaths reported in England and arranges them by the date of death rather than the date of announcement. So for example, if we take the total of 778 UK deaths announced on 14th April, 744 occurred in England, but only 122 of these occurred on 13th April. Another 319 occurred on 12th, 132 on the 11th, 63 on 10th and the remaining 108 on previous days. This breakdown of the announcement \u2026gures is fairly typical and reveals that at any one time, there has been a large backlog of unreported deaths in England, which in \u2021ate the \u2026gures announced later. We estimate that on 13th April there were a staggering 4; 800 deaths that had occurred but not yet been reported. Our methodology is based on our analysis of the reporting lags seen between March 31 and April 13 and is explained in Appendix 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "10 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. We initially undertook this exercise to assess the scale and structure of the reporting lag. However, we found that this was stable enough from day to day to allow us to estimate the \u2026nal number of deaths in any day by suitably adjusting the NHS England daily \u2026gures. Their \u2026gures for the most recent days can be misleading, since they tend to dip because of the reporting lag. Figure 5 shows the daily allocation published on 14 April for example. However, we can use the analysis of the reporting lags in previous weeks to make an allowance for this, as explained in Appendix 1. This adjusted series is also shown the \u2026gure. We exclude the \u2026gures for 13 April because the number of deaths reported on the day of death is too small to provide a reliable estimate of the true number. Figure 6 shows this alongside the English data arranged by the date of announcement rather than the date of death. On a typical day, these English \u2026gures make up 90% of the UK headline total.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 535,
                    "end": 543,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 941,
                    "end": 949,
                    "text": "Figure 6",
                    "ref_id": null
                }
            ],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "11 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "Re \u2021ecting the larger number of deaths on this measure, the regression returns a much higher estimate of the \u2026nal size of the epidemic, K = 18; 906, than the announced data set does. This coe\u00a2 cient is better determined statistically, as is the reproduction coe\u00a2 cient: r = 0:2338: Figure 7 shows the model \u2026t and extrapolation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 282,
                    "end": 290,
                    "text": "Figure 7",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "12 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . M a r 0 5 M a r 0 7 M a r 0 9 M a r 1 1 M a r 1 3 M a r 1 5 M a r 1 7 M a r 1 9 M a r 2 1 M a r 2 3 M a r 2 5 M a r 2 7 M a r 2 9 M a r 3 1 A p r 0 2 A p r 0 4 A p r 0 6 A p r 0 8 A p r 1 0 A p r 1 2 A p r 1 4 A p r 1 6 A p r 1 8 A p r 2 0 A p r 2 2 A p r 2 4 A p r 2 6 A p r 2 8 A p r 3 0 2020 0,000 This is relatively easy to evaluate in these models using stochastic simulations. Please see Appendix 2 for the technical detail.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": "There are two sources of uncertainty to evaluate. The \u2026rst is the additive equation error term e t , geared up by the volatility term. This source of uncertainty builds up initially with the horizon of the forecast, but eventually declines to zero as the process converges to its limit K. The second source of uncertainty concerns the parameters. This is indicated by their estimated standard errors (and covariances). Given these values, a random number generator is used to simulate values of e t and errors in the parameter estimates, which are then fed back into the equation dynamics. Repeating this exercise 100; 000 times gives 100; 000 paths for the pattern of infections and deaths due to the virus, which can be used to construct fan charts like Figures 3   and 4 , which show the results for the number of deaths. This clearly illustrates the huge range of uncertainty still associated with any forecast at this stage of the epidemic.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 756,
                    "end": 773,
                    "text": "Figures 3   and 4",
                    "ref_id": null
                }
            ],
            "section": "Modeling the NHS England date of death data"
        },
        {
            "text": ". CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 There are many ways of analyzing the economy and the same is true of an epidemic. On the one hand, we need detailed structural models to analyze the likely e\u00a4ects of public health interventions like the current lock-down and on the other we need ways of tracking the progression of the virus and assessing its likely evolution. At the moment for example, some commentators are trying to say where we are on 'the curve'",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "and use the experience of other countries that are further along this curve to judge what is likely to happen here. However, as recent experience has shown, it is notoriously di\u00a2 cult to distinguish signal from noise in daily data. It is very easy to make the mistake of thinking that two swallows make a summer. Moreover, the evolution of this virus has di\u00a4ered between countries.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "Our approach to this problem, based on our experience of using a range of di\u00a4erent approaches to economic forecasting over the years, is that when it comes to short term forecasting, it is very hard to beat a simple time series model. These models are good at allowing for the noise in month to month observation, extracting the trend and projecting it forward. We believe that the same is true of the day to day \u2026gures released by PHE and our regression models are designed to exploit this. We are con\u2026dent that the tide has turned and that taking one day with the next, the national \u2026gures for infections, hospital admissions and deaths from this virus will now start to fall back.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": ". CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https: //doi.org/10.1101 //doi.org/10. /2020 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 102,
                    "text": "//doi.org/10.1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 122,
                    "text": "//doi.org/10. /2020",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https: //doi.org/10.1101 //doi.org/10. /2020 We can compound these percentage revisions going backwards in time to get an multiplicative adjustment factor, which, when applied the unadjusted data gives an estimate of the likely \u2026nal value. These are also depicted in Figure 8 . This shows that the number of deaths reported on the day they occurred is on average revised up by a factor of 4:7. After the \u2026rst revision it is subsequently revised by a factor of 2:3 and so on. These adjustment factors are shown in Figure 8 . Applying these factors to the running totals published by NHSE gives our adjusted value. The series for the 13th April are depicted in Figure 5 . Finally, the cumulative di\u00a4erence between these two series gives an estimate of the number of deaths that have occurred but not been announced. This stood at 4; 800 on 13th April. The estimate for 12th April is not shown since the adjusted value of the number of deaths reported on the day they occurred is very unreliable. However, we \u2026nd that this adjustment procedure o\u00a4ers a good indicator after the \u2026rst and second revision.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 102,
                    "text": "//doi.org/10.1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 122,
                    "text": "//doi.org/10. /2020",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 345,
                    "end": 353,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 591,
                    "end": 599,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 737,
                    "end": 745,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "13"
        },
        {
            "text": "Finally, the cumulative di\u00a4erence between the published and adjusted series gives an estimate of the number of deaths that have occurred but not been announced. This stood at 4; 800 on 13th April. A spreadsheet setting out these calculations is available from the authors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "13"
        },
        {
            "text": "We analyse the uncertainty surrounding these forecasts using stochastic simulations. There are two sources of uncertainty to evaluate. The \u2026rst source of uncertainty concerns the parameters. This is indicated by their estimated standard errors and covariances. To capture the correlation between the parameter estimates, we 16 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 decompose the variance-covariance matrix of the estimates using the Cholesky decomposition and generate the new set of parameters as e s = b + C s ;",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "where b is a 3 1 vector of maximum likelihood parameter estimates, C is the lower-triangular of the variance matrix of b and s is a 3 1 vector of standard normal variable generated by a random number generator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "The second source of uncertainty comes from the additive equation error term e t , geared up by the volatility term. This uncertainty builds up initially with the horizon of the forecast, but eventually declines to zero as the process converges to its limit K. Given the (randomized) parameter values, a random number generator of a standard normal variable is used to simulate values of e t , which are then fed back into the dynamics equation (8).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "The inconvenient feature of this simulation approach is that as the process approaches the steady-state K, the volatility of the shocks dies out, e\u00a4ectively leaving us only with the parameter uncertainty at the sample. For example, consider two extreme scenarios: one when, by chance, all the unexpected shocks are positive and in the other all unexpected shocks are negative. These shocks have only some limited impact on the forecasts in the middle horizon, but eventually in about three weeks the forecasts are exactly the same.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "It is rather reasonable to expect that e.g. a large realization of the random shock e t (which could result from underestimation of the K value) should result in an upward revision of the steady-state. Therefore we propose the following recursive method to update the expectations about the steady-state. Assume that we are at time T , i.e. the end of the estimation sample. Denote the estimated K by K T . The model predicts that, absent random shocks, the process will change by:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "while in fact the (simulated) realization of the process is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "At this point, the unexpected part of the process realization ( D 1 T (1 D T =K 0 ) 1 e T +1 ) can be considered a contribution to the \u2026nal value of the steady-state. The value of K that is consistent with this realization is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "17 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 Thus, at time T + 1 we update of the steady-state as",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "Note that for if the unexpected shock is zero and the value of the realized process is equal to its expectation at time T as in (12), then K T +1 = K T . In the next period T + 2 we repeat this procedure and proceed in this manner until the end of our forecast horizon.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "Summarizing, we randomize the parameter values and use them to generate arti\u2026cial path of the process simulating the random shocks e t . At each step we update the steady-state K. Repeating this procedure 100; 000 times gives 100; 000 paths for the pattern of infections and deaths due to the virus, which can be used to construct fan charts like Figures 3 and 4 , which show the results for the number of deaths. This clearly illustrates the huge range of uncertainty still associated with any forecast at this stage of the epidemic.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 347,
                    "end": 362,
                    "text": "Figures 3 and 4",
                    "ref_id": null
                }
            ],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "18 . CC-BY-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10. 1101 /2020 ",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "1101",
                    "ref_id": null
                },
                {
                    "start": 103,
                    "end": 108,
                    "text": "/2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Appendix 2: Stochastic simulations"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A Parametric Nonlinear Model of Term Structure Dynamics",
            "authors": [
                {
                    "first": "D.-H",
                    "middle": [],
                    "last": "Ahn",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Review of Financial Studies",
            "volume": "12",
            "issn": "4",
            "pages": "721--762",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Estimation of the \u2026nal size of the coronavirus epidemic by the logistic model",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Batista",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Time Series Analysis: Forecasting and Control",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Box",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Jenkins",
                    "suffix": ""
                }
            ],
            "year": 1976,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A Theory of the Term Structure of Interest Rates",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Cox",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ingersoll",
                    "suffix": ""
                },
                {
                    "first": "Jonathan",
                    "middle": [
                        "E"
                    ],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Ross",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "Econometrica",
            "volume": "53",
            "issn": "2",
            "pages": "385--407",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Di\u00a4erential operators with the positive maximum property",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Feller",
                    "suffix": ""
                }
            ],
            "year": 1959,
            "venue": "Illinois Journal of Mathematics",
            "volume": "3",
            "issn": "2",
            "pages": "182--186",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "A contribution to the mathematical theory of epidemics",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "O"
                    ],
                    "last": "Kermack",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Mckendrick",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "T"
                    ],
                    "last": "Walker",
                    "suffix": ""
                }
            ],
            "year": 1927,
            "venue": "Proceedings of the Royal Society of London. Series A",
            "volume": "115",
            "issn": "772",
            "pages": "375--393",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Macroeconomics and Reality",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Sims",
                    "suffix": ""
                }
            ],
            "year": 1980,
            "venue": "Econometrica",
            "volume": "48",
            "issn": "1",
            "pages": "1--48",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Notice sur la loi que la population pursuit das son accroissement",
            "authors": [
                {
                    "first": "P.-F",
                    "middle": [],
                    "last": "Verhulst",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Correspondance Math\u00e9matique et Physique",
            "volume": "10",
            "issn": "",
            "pages": "113--121",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Figure 1",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The number of deaths on each day, before and after adjustment.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Deaths by day they were announced and the day they occurred.These adjusted date of death data (ADD) o\u00a4er another way to monitor the e\u00a4ect of the virus on mortality.The regression model give this result:ADD t ADD t 1 ADD t =18; 906) 3=4 e t :14 March 2020 -12 April",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Modeling the adjusted date of death data.6 Allowing for uncertainty Figures 1 and 2 project these data forward dynamically given the estimated parameter values assuming that the shocks represented by e t are zero. However, like economic forecasts, they are subject to uncertainty.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Revisions and adjustment factors by vintage",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "The date of death data set released by NHSE is available at: https://www.england.nhs.uk/statistics/statistical-work-areas/covid-19-daily-deaths/ This takes the deaths reported in England and arranges them by the date of death rather than the date of announcement. Two tables are published each day. The \u2026rst is for the newly announced deaths, which are arranged in terms the date of death. (They are also broken down in terms of age, region and local authority but we focus on the total for England.) The second table cumulates these \u2026gures to get the running total for the number of deaths that occurred on each day. These build up over time as deaths are reported and announced.We treat the \u2026rst of these tables as revisions, similar to the revisions seen in economic data, which gives di\u00a4erent vintages for di\u00a4erent release dates. We \u2026rst express the \u2026gure for the revision for each day as a percentage increase on the previous cumulative value for that day. This immediately reveals that the lag is very signi\u2026cant. In particular, the number of deaths reported on the day they occurred is a very unreliable guide to the \u2026nal total. In the \u2026rst half of April, it was on average revised up by 237% the next day (vintage 1), 45% the day after (vintage 2) 20% the day after that (vintage 3), and so on and so forth.These average revisions are shown in terms of their vintage in Figure 8 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1378,
                    "end": 1386,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Appendix 1: Analyzing the NHSE data"
        }
    ]
}