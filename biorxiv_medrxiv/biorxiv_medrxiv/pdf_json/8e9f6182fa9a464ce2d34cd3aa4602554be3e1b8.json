{
    "paper_id": "8e9f6182fa9a464ce2d34cd3aa4602554be3e1b8",
    "metadata": {
        "title": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network",
        "authors": [
            {
                "first": "Asmaa",
                "middle": [],
                "last": "Abbas",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Assiut University",
                    "location": {
                        "settlement": "Assiut",
                        "country": "Egypt"
                    }
                },
                "email": ""
            },
            {
                "first": "Mohammed",
                "middle": [
                    "M"
                ],
                "last": "Abdelsamea",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Assiut University",
                    "location": {
                        "settlement": "Assiut",
                        "country": "Egypt"
                    }
                },
                "email": "*mohammed.abdelsamea@bcu.ac.uk"
            },
            {
                "first": "Mohamed",
                "middle": [],
                "last": "Medhat Gaber",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Birmingham City University",
                    "location": {
                        "settlement": "Birmingham",
                        "country": "UK"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Chest X-ray is the first imaging technique that plays an important role in the diagnosis of COVID-19 disease. Due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks (CNN s) for image recognition and classification. However, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. In this paper, we validate and adapt our previously developed CNN, called Decompose, Transfer, and Compose (DeTraC ), for the classification of COVID-19 chest X-ray images. DeTraC can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. The experimental results showed the capability of DeTraC in the detection of COVID-19 cases from a comprehensive image dataset collected from several hospitals around the world. High accuracy of 95.12% (with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of 93.36%) was achieved by DeTraC in the detection of COVID-19 X-ray images from normal, and severe acute respiratory syndrome cases. 12 disease within computed tomography (CT ). In [3], a modified version of ResNet-50 13 pre-trained network has been provided to classify CT images into three classes: healthy, 14 COVID-19 and bacterial pneumonia. Chest x-ray images (CXR) were used in [4] by a 15 CNN constructed based on various ImageNet pre-trained models to extract the high 16 : medRxiv preprint 150 COVID-19 images, we compare it with ResNet18 using the same settings. ResNet18 151 achieved accuracy of 92.5%, sensitivity of 65.01%, specificity of 94.3%, and precision of 152 94.5%. 153 Fig 3. The learning curve accuracy and error obtained by DeTraC-ResNet18 model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Diagnosis of COVID-19 is typically associated with both the symptoms of pneumonia 2 and Chest X-ray tests. Chest X-ray is the first imaging technique that plays an 3 important role in the diagnosis of COVID-19 disease. Fig. 1 shows a negative example 4 of a normal chest x-ray, a positive one with COVID-19, and a positive one with the 5 severe acute respiratory syndrome (SARS). 6 In the last few months, World Health Organization (WHO) has declared that a new 7 virus called COVID-19 has been spread aggressively in several countries around the 8 world [1] . Fast detection of the COVID-19 can be contributed to control the spread of 9 the disease. One of the most successful algorithms that have been proved its ability to 10 diagnosis medical images with high accuracy is convolution neural network (CNN ). For 11 example, in [2] , a CNN was applied based on Inception network to detect COVID-19 level features. Those features were fed into a Support Vector Machine SVM as a 17 machine learning classifier in order to detect the COVID-19 cases. Moreover, in [5] , a 18 CNN architecture called COVID-Net based on transfer learning was applied to classify 19 the CXR images into four classes: normal, bacterial infection, non-COVID and 20 COVID-19 viral infection. 21 Several classical machine learning approaches have been previously used for 22 automatic classification of digitised chest images [6, 7] . For instance, in [8] , three 23 statistical features were calculated from lung texture to discriminate between malignant 24 and benign lung nodules using a support vector machine classifier. A grey-level 25 co-occurrence matrix method was used with Backpropagation Network [9] to classify 26 images from being normal or cancerous. With the availability of enough annotated 27 images, deep learning approaches [10, 11] have demonstrated their superiority over the 28 classical machine learning approaches. CNN architecture is one of the most popular 29 deep learning approaches with superior achievements in the medical imaging domain [12] . 30 The primary success of CNN is due to its ability to learn features automatically from 31 domain-specific images, unlike the classical machine learning methods. The popular 32 strategy for training CNN architecture is to transfer learned knowledge from a 33 pre-trained network that fulfilled one task into a new task [13] . This method is faster 34 and easy to apply without the need for a huge annotated dataset for training; therefore 35 many researchers tend to apply this strategy especially with medical imaging.",
            "cite_spans": [
                {
                    "start": 555,
                    "end": 558,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 830,
                    "end": 833,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1062,
                    "end": 1065,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1400,
                    "end": 1403,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1404,
                    "end": 1406,
                    "text": "7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1426,
                    "end": 1429,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1682,
                    "end": 1685,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1818,
                    "end": 1822,
                    "text": "[10,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1823,
                    "end": 1826,
                    "text": "11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 2043,
                    "end": 2047,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 2050,
                    "end": 2052,
                    "text": "30",
                    "ref_id": null
                },
                {
                    "start": 2370,
                    "end": 2374,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 219,
                    "end": 225,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": ""
        },
        {
            "text": "Class decomposition [14] has been proposed with the aim of enhancing low variance 37 classifiers facilitating more flexibility to their decision boundaries. In this paper, we 38 adapt and validate DeTraC [15] for the classification of COVID-19 in chest x-ray images 39 1 . This is by adding a class decomposition layer to the pre-trained models. The class 40 decomposition layer aims to partition each class within the image dataset into several 41 sub-classes and then assign new labels to the new set, where each subset is treated as an 42 independent class, then those subsets are assembled back to produce the final 43 predictions. For the classification performance evaluation, we used images of chest x-ray 44 collected from several hospitals and institutions. The dataset provides complicated 45 computer vision challenging problems due to the intensity inhomogeneity in the images 46 and irregularities in the data distribution. Then we apply the class-decomposition layer of DeTraC to simplify the local structure 52 of the data distribution. In the second phase, the training is accomplished using a 53 sophisticated gradient descent optimisation method. Finally, we use the 54 class-composition layer of DeTraC to refine the final classification of the images. As pre-trained CNN model using the collected chest X-ray image dataset. We used the 64 off-the-shelf CNN features of pre-trained models on ImageNet (where the training is 65 accomplished only on the final classification layer) to construct the image feature space. 66 However, due to the high dimensionality associated with the images, we applied PCA to 67 project the high-dimension feature space into a lower-dimension, where highly 68 correlated features were ignored. This step is important for the class decomposition to 69 produce more homogeneous classes, reduce the memory requirements, and improve the 70 efficiency of the framework. . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 24,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 204,
                    "end": 208,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "36"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "36"
        },
        {
            "text": "where n is the number of images, m is the number of features, and k is the number 75 of classes. For class decomposition, we used k-means clustering [16] to further divide 76 each class into homogeneous sub-classes (or clusters), where each pattern in the original 77 class L is assigned to a class label associated with the nearest centroid based on the 78 squared euclidean distance (SED):",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 153,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "36"
        },
        {
            "text": "where centroids are denoted as c j .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "36"
        },
        {
            "text": "Once the clustering is accomplished, each class in L will further divided into k 81 subclasses, resulting in a new dataset (denoted as dataset B).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "80"
        },
        {
            "text": "Accordingly, the relationship between dataset A and B can be mathematically 83 described as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "82"
        },
        {
            "text": "where the number of instances in A is equal to B while C encodes the new labels of 85 the subclasses (e.g. C = {l 11 , l 12 , . . . , l 1k , l 21 , l 22 , . . . , l 2k , . . . l ck }). Consequently A and 86 B can be rewritten as: For fine-tuning the parameters, the learning rate for all the CNN layers was fixed to 92 0.0001 except for the last fully connected layer (was 0.01), the min batch size was 64 93 with minimum 256 epochs, 0.001 was set for the weight decay to prevent the overfitting 94 through training the model, and the momentum value was 0.9. With the limited [y j ln z x j",
            "cite_spans": [],
            "ref_spans": [],
            "section": "82"
        },
        {
            "text": "where x j is the set of input images in the training, y j is the ground truth labels 100 while z(\u00b7) is the predicted output from a softmax function. In this work we used a combination of two datasets:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "82"
        },
        {
            "text": "\u2022 80 samples of normal CXRs (with 4020 \u00d7 4892 pixels) from the Japanese Society 112 of Radiological Technology (JSRT ) [19, 20] .",
            "cite_spans": [
                {
                    "start": 119,
                    "end": 123,
                    "text": "[19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 124,
                    "end": 127,
                    "text": "20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "111"
        },
        {
            "text": "\u2022 Chest X-ray images of [21] , which contains 105 and 11 samples of COVID-19 and 114 SARS (with 4248 \u00d7 3480 pixels). 115 We applied different data augmentation techniques to generate more samples such functions and three different kernel filters. We adopted the last fully connected layer 125 into three classes and initialised the weight parameters for our specific classification 126 task. For class decomposition process, we used k-means clustering [16] . In this step, as 127 pointed out in [15] , we selected k = 2 and hence each class in L is further divided into 128 two clusters (or subclasses), resulting in a new dataset (denoted as dataset B) with six 129 classes (norm 1, norm 2, COVID19 1,COVID19 2, SARS 1, and SARS 2), see Table 1 . . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 28,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 117,
                    "end": 120,
                    "text": "115",
                    "ref_id": null
                },
                {
                    "start": 452,
                    "end": 456,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 495,
                    "end": 499,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 738,
                    "end": 745,
                    "text": "Table 1",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "113"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . was trained based on deep learning mode. For performance evaluation, we adopted some 145 metrics from the confusion matrix such as accuracy, sensitivity, specificity, and precision. 146 The results were reported and summarised in table 2.",
            "cite_spans": [
                {
                    "start": 260,
                    "end": 263,
                    "text": "146",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "113"
        },
        {
            "text": "We plot the learning curve accuracy and loss between training and test as shown in 148 Fig 3. Also, the Area Under the receiver curve (AUC) was computed as shown in Fig 4. 149 To demonstrate the robustness of DeTraC-ResNet18 in the classification of . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 175,
                    "text": "Fig 4. 149",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 87,
                    "end": 93,
                    "text": "Fig 3.",
                    "ref_id": null
                }
            ],
            "section": "147"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20047456 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "147"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Coronavirus disease 2019 ( COVID-19): situation report, 51",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19). medRxiv",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep learning Enables Accurate Diagnosis of Novel Coronavirus (COVID-19) with CT images. medRxiv",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Detection of Coronavirus Disease (COVID-19) Based on Deep Features",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "K"
                    ],
                    "last": "Sethy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Behera",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Artificial neural network-based classification system for lung nodules on computed tomography scans",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Dand\u0131l",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ek\u015fi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "\u00d6zkan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kurt\u00f6k",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Canan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "6th International conference of soft computing and pattern recognition (SoCPaR)",
            "volume": "",
            "issn": "",
            "pages": "382--386",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Lung cancer classification using neural networks for CT images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kuruvilla",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Gunavathi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "113",
            "issn": "",
            "pages": "202--209",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Lung cancer detection using fuzzy auto-seed cluster means morphological segmentation and SVM classifier",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Manikandan",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Bharathi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of medical systems",
            "volume": "40",
            "issn": "7",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Lung tumour detection and classification using EK-Mean clustering",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sangamithraa",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Govindaraju",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 International Conference on Wireless Communications",
            "volume": "",
            "issn": "",
            "pages": "2201--2206",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Lung pattern classification for interstitial lung diseases using a deep convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Anthimopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Christodoulidis",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ebner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Christe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mougiakakou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE transactions on medical imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1207--1216",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Computer aided lung cancer diagnosis with deep learning algorithms",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Medical imaging 2016: computer-aided diagnosis",
            "volume": "9785",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "nature",
            "volume": "521",
            "issn": "7553",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A survey on transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Transactions on knowledge and data engineering",
            "volume": "22",
            "issn": "10",
            "pages": "1345--1359",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Class decomposition via clustering: a new framework for low-variance classifiers",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vilalta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Achari",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "F"
                    ],
                    "last": "Eick",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Third IEEE International Conference on Data Mining",
            "volume": "",
            "issn": "",
            "pages": "673--676",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "DeTraC: Transfer Learning of Class Decomposed Medical Images in Convolutional Neural Networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Abbas",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Abdelsamea",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Gaber",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Top 10 algorithms in data mining. Knowledge and information systems",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Quinlan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Motoda",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "14",
            "issn": "",
            "pages": "1--37",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Selecting and interpreting measures of thematic classification accuracy. Remote sensing of Environment",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "V"
                    ],
                    "last": "Stehman",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "",
            "volume": "62",
            "issn": "",
            "pages": "77--89",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Lung Segmentation in Chest Radiographs Using Anatomical Atlases With Nonrigid Registration",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Palaniappan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Musco",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "33",
            "issn": "2",
            "pages": "577--590",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2013.2290491"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Automatic Tuberculosis Screening Using Chest Radiographs",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jaeger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karargyris",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Candemir",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Folio",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Siegelman",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Callaghan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "33",
            "issn": "2",
            "pages": "233--245",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2013.2284099"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "COVID-19 image data collection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1097--1105",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Alemi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Thirty-first AAAI conference on artificial intelligence",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Examples of a) normal, b) COVID-19, and c) SARS chest x-ray images.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "model consists of three phases. In the first phase, we train the backbone 50 pre-trained CNN model of DeTraC to extract deep local features from each image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The developed code is available at https://github.com/asmaa4may/DeTraC COVId19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Decompose, Transfer, and Compose (DeTraC ) model for the detection of COVID-19 from chest X-ray images.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "55 illustrated in Fig. 2, class decomposition and composition components are added 56 respectively before and after knowledge transformation from an ImageNet pre-trained 57 CNN model. The class decomposition component aiming at partitioning each class 58 within the image dataset into k sub-classes, where each subclass is treated 59 independently. Then those sub-classes are assembled back using the class-composition 60 component to produce the final classification of the original image dataset. 61 Deep feature extraction 62 A shallow-tuning mode was used during the adaptation and training of an ImageNet63",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "that our feature space (PCA's output) is represented by a 2-D matrix 73 (denoted as dataset A), and L is a class category. A and L can be",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "95 availability of training data, stochastic gradient descent (SGD) can heavily be 96 fluctuating the objective/loss function and hence overfitting can occur. To improve 97 convergence and overcome overfitting, the mini-batch of stochastic gradient descent 98 (mSGD) was used to minimise the objective function, E(\u00b7), with cross-entropy loss",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "the class decomposition layer of DeTraC, we divide each class within the image 103 dataset into several sub-classes, where each subclass is treated as a new independent 104 class. In the composition phase, those sub-classes are assembled back to produce the 105 final prediction based on the original image dataset. For performance evaluation, we 106 adopted Accuracy (ACC), Specificity (SP) and Sensitivity (SN) metrics from the 107 confusion matrix (as pointed out in [18]).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "as: flipping up/down and right/left, translation and rotation using random five different 117 angles. This process resulted in a total of 1764 samples. Also, a histogram modification 118 technique was applied to enhance the contrast of each image.119 0.1 Class decomposition based on deep features 120 We used AlexNet [22] pre-trained network based on shallow learning mode to extract 121 discriminative features of the three original classes. AlexNet is composed of 5 122 convolutional layers to represent learned features, 3 fully connected layers for the 123 classification task. AlexNet uses 3 \u00d7 3 max-pooling layers with ReLU activation 124",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "experiments in our work have been carried out in MATLAB 2019a on a PC with 132 the following configuration: 3.70 GHz Intel(R) Core(TM) i3-6100 Duo, NVIDIA 133 Corporation with the donation of the Quadra P5000GPU, and 8.00 GB RAM.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "The ROC analysis curve by training DeTraC model based on ResNet pre-trained network Discussion 154 Training CNN s can be accomplished using two different strategies. They can be used as 155 an end-to-end network, where an enormous number of annotated images must be 156 provided (which is impractical in medical imaging). Alternatively, transfer learning 157 usually provides an effective solution with the limited availability of annotated images 158 by transferring knowledge from pre-trained CNN s (that have been learned from a 159 bench-marked large-scale image dataset) to the specific medical imaging task. Transfer 160 learning can be further accomplished by three main scenarios: shallow-tuning, 161 fine-tuning, or deep-tuning. However, data irregularities, especially in medical imaging 162 applications, remain a challenging problem that usually results in miscalibration 163 between the different classes in the dataset. CNN s can provide an effective and robust 164 solution for the detection of the COVID-19 cases from chest X-ray CXR images and this 165 can be contributed to control the spread of the disease. Here, we adopt and validate our 166 previously developed deep convolutional neural network, we called DeTraC, to deal with 167 such a challenging problem by exploiting the advantages of class decomposition within 168 the CN N s for image classification. DeTraC achieved high accuracy of 95.12% with 169 ResNet on CXR images. 170 Conclusion 171 In this paper, we used DeTraC deep CNN architecture that relies on a class 172 decomposition approach for the classification of COVID-19 images in a comprehensive 173 dataset of chest X-ray images. DeTraC showed effective and robust solutions for the 174 classification of COVID-19 cases and its ability to cope with data irregularity and the 175 limited number of training images too.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "11 a 11 . . . a 1m l 1 a 21 a 22 . . .",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": ") freezing the weights of low-level layers and update weighs of high-level layers.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Samples distribution in each class of chest X-ray dataset before and after class decomposition.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}