{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs=[\"biorxiv_medrxiv\"]\n",
    "docs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in dirs:\n",
    "    for file in os.listdir(f\"{d}/{d}/pdf_json\"):\n",
    "        #print(file)\n",
    "        file_path=f\"{d}/{d}/pdf_json/{file}\"\n",
    "        j=json.load(open(file_path,\"rb\"))\n",
    "        full_text=\"\"\n",
    "        abstract=j['abstract']\n",
    "        title=j['metadata']['title']\n",
    "        for text in j['body_text']:\n",
    "            full_text+=text['text']+'\\n\\n'\n",
    "        docs.append([title,abstract,full_text])\n",
    "\n",
    "df=pd.DataFrame(docs,columns=['title','abstract','full_text'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>During the past three months, a new coronaviru...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Relationship between Average Daily Temperature...</td>\n",
       "      <td>The rapid outbreak of the new Coronavirus pand...</td>\n",
       "      <td>The outbreak of infectious diseases has always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>The fast accumulation of viral metagenomic dat...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to dir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...   \n",
       "1  Analysis Title: Regaining perspective on SARS-...   \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...   \n",
       "3  Relationship between Average Daily Temperature...   \n",
       "4  CHEER: hierarCHical taxonomic classification f...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1  During the past three months, a new coronaviru...   \n",
       "2                                                      \n",
       "3  The rapid outbreak of the new Coronavirus pand...   \n",
       "4  The fast accumulation of viral metagenomic dat...   \n",
       "\n",
       "                                           full_text  \n",
       "0  VP3, and VP0 (which is further processed to VP...  \n",
       "1  In December 2019, a novel coronavirus, SARS-Co...  \n",
       "2  The 2019-nCoV epidemic has spread across China...  \n",
       "3  The outbreak of infectious diseases has always...  \n",
       "4  Metagenomic sequencing, which allows us to dir...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_abstract = [] \n",
    "for value in df[\"abstract\"]: \n",
    "    if (len(value) > 0): \n",
    "        new_abstract.append(value[0]['text'])\n",
    "    else: \n",
    "        new_abstract.append(\"\") \n",
    "       \n",
    "df['abstract'] = new_abstract\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data-lower the dataframe, remove stopwords,tokenized text into sentence then into words\n",
    "xtitleLower = df['title'].to_string(na_rep='').lower()\n",
    "xtitle = df['title'].str.lower()\n",
    "xtitleLower = df['abstract'].to_string(na_rep='').lower()\n",
    "xtitle = df['abstract'].str.lower()\n",
    "xtitleLower = df['full_text'].to_string(na_rep='').lower()\n",
    "xtitle = df['full_text'].str.lower()\n",
    "stop = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['full_text'] = df['full_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#df['stemmed'] = df['unstemmed'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "#df = df.drop(columns=['unstemmed'])\n",
    "arr = df.to_numpy()\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "for i in range(len(arr)):\n",
    "    for j in range(len(arr[i])):\n",
    "        arr[i][j] = word_tokenize(arr[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'count', ':', '194', '22', 'Text', 'word', 'count', ':', '5168', '23', '24', '25', 'author/funder', '.', 'All', 'rights', 'reserved', '.', 'No', 'reuse', 'allowed', 'without', 'permission', '.', 'Abstract', '27', 'The', 'positive', 'stranded', 'RNA', 'genomes', 'of', 'picornaviruses', 'comprise', 'a', 'single', 'large', 'open', 'reading', '28', 'frame', 'flanked', 'by', '5′', 'and', '3′', 'untranslated', 'regions', '(', 'UTRs', ')', '.', 'Foot-and-mouth', 'disease', 'virus', '(', 'FMDV', ')', '29', 'has', 'an', 'unusually', 'large', '5′', 'UTR', '(', '1.3', 'kb', ')', 'containing', 'five', 'structural', 'domains', '.', 'These', 'include', 'the', '30', 'internal', 'ribosome', 'entry', 'site', '(', 'IRES', ')', ',', 'which', 'facilitates', 'initiation', 'of', 'translation', ',', 'and', 'the', 'cis-acting', '31', 'replication', 'element', '(', 'cre', ')', '.', 'Less', 'well', 'characterised', 'structures', 'are', 'a', '5′', 'terminal', '360', 'nucleotide', '32', 'stem-loop', ',', 'a', 'variable', 'length', 'poly-C-tract', 'of', 'approximately', '100-200', 'nucleotides', 'and', 'a', 'series', 'of', '33', 'two', 'to', 'four', 'tandemly', 'repeated', 'pseudoknots', '(', 'PKs', ')', '.', 'We', 'investigated', 'the', 'structures', 'of', 'the', 'PKs', '34', 'by', 'selective', '2′', 'hydroxyl', 'acetylation', 'analysed', 'by', 'primer', 'extension', '(', 'SHAPE', ')', 'analysis', 'and', '35', 'determined', 'their', 'contribution', 'to', 'genome', 'replication', 'by', 'mutation', 'and', 'deletion', 'experiments', '.', '36', 'SHAPE', 'and', 'mutation', 'experiments', 'confirmed', 'the', 'importance', 'of', 'the', 'previously', 'predicted', 'PK', '37', 'structures', 'for', 'their', 'function', '.', 'Deletion', 'experiments', 'showed', 'that', 'although', 'PKs', 'are', 'not', 'essential', '38']\n"
     ]
    }
   ],
   "source": [
    "print(arr[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
